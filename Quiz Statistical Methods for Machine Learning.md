# Quiz list for the written test

- **Write the formula for the square loss, the zero-one loss, and the logarithmic loss.**
	The square loss formula is $\ell(y, \widehat{y}) = (y - \widehat{y})^2$;
	the zero-one loss is $\ell(y, \widehat{y}) = \cases{1 \quad \text{ if } y \neq \widehat{y} \cr \cr 0 \quad \text{ otherwise }}$
	the logarithmic loss is $\ell(y, \widehat{y}) = \cases{\ln{\frac{1}{\widehat{y}}} \quad \text{ if } y = 1 \cr \cr \ln{\frac{1}{1 - \widehat{y}}} \quad \text{ if } y = 0}$
- **What is the mathematical definition of predictor?**
	Given the set of all possible data points for a given learning problem $\mathcal{X}$ and given the set of all possible labels $\mathcal{Y}$, a predictor is a function $f: \mathcal{X} \to \mathcal{Y}$ mapping data points to labels (or $f: \mathcal{X} \to \mathcal{Z}$ if the predictions belong to a set $\mathcal{Z}$ different from $\mathcal{Y}$).
- **What does a learning algorithm receive in input? And what does it produce in output?**
	A learning algorithm receives a training set in input and it produces a predictor in output. A training set $S$ is a set of examples $\{(x_1, y_1), ..., (x_m, y_m)\}$.
- **Write the mathematical formula defining the ERM algorithm over a class $\mathcal{H}$ of predictors. Define the main quantities occurring in the formula.**
	Given a class $\mathcal{H}$ of predictors and a loss function $\ell$, the Empirical Risk Minimizer is the learning algorithm that outputs some predictors minimizing the empirical risk on the training set $S$. The mathematical formula is $\widehat{f} \in \underset{f \in \mathcal{H}}{\operatorname{argmin}} \ell_S(f)$. The $\widehat{f} \in$ notation takes into account the fact that there could be multiple $f \in \mathcal{H}$ minimizing the training error.
- **How do you define overfitting and underfitting in terms of behavior of an algorithm on training and test set?**
	it is possible to give specific names to these two ways of failing when returning a predictor with high test error for a generic learning algorithm $A$:
	- if $A$ fails by returning predictors with high training error, then we say that $A$ is **underfitting**;
	- if $A$ fails by returning predictors with low training error, then we say that $A$ is **overfitting**.
- **Name and describe three reasons why labels may be noisy.**
	Noise may occur for at least three (not mutually exclusive) reasons:
	1) **human in the loop**: the labels are assigned by a human annotator who decides the “true” label for each data point. In this case, different annotators may have different opinions;
	2) **epistemic uncertainty**: each data point is represented by a feature vector $x$ that does not contain enough information to uniquely determine the label;
	3) **aleatoric uncertainty**: the feature vector $x$ representing a data point is obtained through noisy measurements. The label associated with a given $x$ is then stochastic because the same $x$ could have been generated by different data points.
- **Write a short pseudo-code for the $k-NN$ algorithm for binary classification.**
- **Is $k-NN$ more likely to overfit when $k$ is large or small?**
- **Write a short pseudo-code for building a tree classifier based on a training set.**
- **What is the property of a splitting criterion $\psi$ ensuring that the training error of a tree classifier does not increase after a split? Bonus points if you justify your answer with a proof.**
- **Name at least two splitting criteria $\psi$ used in practice to build tree classifiers. Bonus points if you write their formula.**
- **What are the elements of a learning problem in statistical learning?**
	...
- **Write the formula for the statistical risk of a predictor $h$ with respect to a generic loss function**.
- **Write the formula for the Bayes optimal predictor for a generic loss function.**
- **Write the formula for Bayes optimal predictor and Bayes risk for the zero-one loss.**
- **Can the Bayes risk for the zero-one loss be zero? If yes, then explain how.**
- **Write the formula for Bayes optimal predictor and Bayes risk for the square loss.**
- **Explain in mathematical terms the relationship between test error and statistical risk.**
- **State the Chernoff-Hoeffding bounds.**
- **Write the bias-variance decomposition for a generic learning algorithm $A$ and associate the resulting components to overfitting and underfitting.**
- **Write the upper bound on the estimation error of ERM run on a finite class of predictors. Bonus points if you justify your answer with a proof.**
- Write the upper bound on the estimation error of ERM run on a the class of complete binary tree predictors with at most NOverfitting often arises when labels are ￼￼noisy￼￼. Namely, when labels ￼￼ are not deterministically associated with data points ￼￼. nodes on d binary features. Bonus points if you justify your answer with a proof.
- Write the bound on the difference between risk and training error for an arbitrary complete binary tree classifier on d binary features in terms of its number Nh of nodes. Bonus points if you justify your answer with a proof.
- Write the formula for the K-fold cross validation estimate. Explain the main quantities occurring in the formula.
- Write a short pseudo-code for computing the nested cross validation estimate.
- Write the mathematical definition of consistency for an algorithm A.
- Write the statement of the no-free-lunch theorem.
- Write the mathematical definition of nonparametric learning algorithm. Define the main quantities occurring in the formula.
- Name one nonparametric learning algorithm and one parametric learning algorithm.
- Write the mathematical conditions on k ensuring consistency for the k-NN algorithm.
- Write the formula for the Lipschitz condition in a binary classification problem.
- Write the rate at which the risk of a consistent learning algorithm for binary classification vanish as a function of the training set size and the dimension under Lipschitz assumptions.
- Explain the curse of dimensionality.
- Write the bound on the risk of 1-NN binary classifier under Lipschitz assumptions.
- Can the ERM over linear classifiers be computed efficiently? Can it be approximated effi- ciently? Motivate your answers.
- Write the system of linear inequalities stating the condition of linear separability for a training set for binary classfication.
- Write the pseudo-code for the Perceptron algorithm.
- Write the statement of the Perceptron convergence theorem. Bonus points if you provide the proof.
- Write the closed-form formula (i.e., not the argmin definition) for the Ridge Regression pre- dictor. Define the main quantities occurring in the formula.
- Write the pseudo-code for the projected online gradient descent algorithm.
- Write the upper bound on the regret of projected online gradient descent on convex functions. Define the main quantities occurring in the bound.
- Write the upper bound on the regret of online gradient descent on σ-strongly convex functions. Define the main quantities occurring in the bound.
- Write the formula for the hinge loss.
- Write the mistake bound for the Perceptron run on an arbitrary data stream for binary classification. Define the main quantities occurring in the bound.
- Write the formula for the polynomial kernel of degree n.
- Write the formula for the Gaussian kernel with parameter γ.
- Write the pseudo-code for the kernel Perceptron algorithm.
- Write the mathematical definition of the linear space HK of functions induced by a kernel K.
- Let f be an element of the linear space HK induced by a kernel K. Write f (x) in terms of K.
- Write the statement of the Perceptron convergence theorem when the Perceptron is run with a kernel K. Define the main quantities occurring in the bound.
- Write the closed-form formula (i.e., not the argmin definition) of the kernel version of the Ridge Regression predictor.
- Write the convex optimization problem with linear constraints that defines the SVM hyperplane in the linearly separable case.
- Write the unconstrained optimization problem whose solution defines the SVM hyperplane when the training set is not necessarily linearly separable.
- Write the bound on the expected value of the SVM objective function achieved by Pegasos. Provide also a bound on the expected squared norm of the loss gradient.
- Write the definition of ε-stability for a learning algorithm.
- Write the value of ε for which SVM is known to be stable. The value depends on the radius X of the ball where the training datapoints live, the training set size m, and the regularization coefficient λ.
- Write the mathematical conditions on the regularization coefficient λ ensuring consistency for the SVM algorithm wih Gaussian kernel.
- Consider the class Fd of all functions of the form f : {−1, 1}d → {−1, 1}. Let FG,sgn be the class of functions computed by a feedforward neural networks with the sgn activation function and graph G = (V, E). Provide asymptotic upper and lower bounds on |V | such that Fd ⊆ FG,sgn.
- Define a class of neural networks for which the ERM problem with the square loss is probably NP-hard.
- Write the update line of the stochastic gradient descent algorithm. Explain the main quantities.
- Write the definition of logistic loss for logistic regression with linear models.
- Write the definition of consistency for surrogate losses.
- Write a sufficient condition for consistency of a surrogate loss.
- Write the formula for Bayes optimal predictor and Bayes risk for the logistic loss.