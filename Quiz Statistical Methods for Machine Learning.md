# Quiz list for the written test

- **Write the formula for the square loss, the zero-one loss, and the logarithmic loss.**
	The square loss formula is $\ell(y, \widehat{y}) = (y - \widehat{y})^2$;
	the zero-one loss is $\ell(y, \widehat{y}) = \cases{1 \quad \text{ if } y \neq \widehat{y} \cr \cr 0 \quad \text{ otherwise }}$
	the logarithmic loss is $\ell(y, \widehat{y}) = \cases{\ln{\frac{1}{\widehat{y}}} \quad \text{ if } y = 1 \cr \cr \ln{\frac{1}{1 - \widehat{y}}} \quad \text{ if } y = 0}$
- **What is the mathematical definition of predictor?(BONUS)**
	Given the set of all possible data points for a given learning problem $\mathcal{X}$ and given the set of all possible labels $\mathcal{Y}$, a predictor is a function $f: \mathcal{X} \to \mathcal{Y}$ mapping data points to labels (or $f: \mathcal{X} \to \mathcal{Z}$ if the predictions belong to a set $\mathcal{Z}$ different from $\mathcal{Y}$).
- **Write the mathematical formula defining the training error of a predictor $h$.**
	The training error or statistical risk is $\ell_s(f) = \frac{1}{m}\sum_{t=1}^{m}\ell(y_t, f(\mathbf{x}_t))$.
- **What does a learning algorithm receive in input? And what does it produce in output?**
	A learning algorithm receives a training set in input and it produces a predictor in output. A training set $S$ is a set of examples $\{(x_1, y_1), ..., (x_m, y_m)\}$, where $x$ is a data point and $y$ is the corresponding label.
- **Write the mathematical formula defining the ERM algorithm over a class $\mathcal{H}$ of predictors. Define the main quantities occurring in the formula.**
	Given a class $\mathcal{H}$ of predictors and a loss function $\ell$, the Empirical Risk Minimizer is the learning algorithm that outputs some predictors minimizing the empirical risk on the training set $S$. The mathematical formula is $\widehat{f} \in \underset{f \in \mathcal{H}}{\operatorname{argmin}} \ell_S(f)$. The $\widehat{f} \in$ notation takes into account the fact that there could be multiple $f \in \mathcal{H}$ minimizing the training error.
- **How do you define overfitting and underfitting in terms of behavior of an algorithm on training and test set?**
	it is possible to give specific names to the two ways of failing when returning a predictor with high test error for a generic learning algorithm $A$:
	- if $A$ fails by returning predictors with high training error, then we say that $A$ is **underfitting**;
	- if $A$ fails by returning predictors with low training error, then we say that $A$ is **overfitting**.
- **Name and describe three reasons why labels may be noisy.**
	Noise may occur for at least three (not mutually exclusive) reasons:
	1) **human in the loop**: the labels are assigned by a human annotator who decides the “true” label for each data point. In this case, different annotators may have different opinions;
	2) **epistemic uncertainty**: each data point is represented by a feature vector $x$ that does not contain enough information to uniquely determine the label;
	3) **aleatoric uncertainty**: the feature vector $x$ representing a data point is obtained through noisy measurements. The label associated with a given $x$ is then stochastic because the same $x$ could have been generated by different data points.
- **Write a short pseudo-code for the $k-NN$ algorithm for binary classification. (BONUS)**
- **Is $k-NN$ more likely to overfit when $k$ is large or small?**
	The learning algorithm suffers from high test error for small values of $k$ (overfitting) and for large values of $k$ (underfitting).
- **Write a short pseudo-code for building a tree classifier based on a training set $S$.**
	1) **initialization**: create $T$ with only the root $\ell$ and let $S_\ell = S$. Let the label associated with the root be the most frequent label in $S_\ell$;
	2) **main loop**: pick a leaf $\ell$ and replace it with an internal node $v$ creating two children $\ell'$ (first child) and $\ell''$ (second child). Pick an attribute $i$ and a test $f : \mathcal{X}_i \to \{1,2\}$. Associate the test $f$ with $v$ and partition $S_\ell$ in the two subsets $S_{\ell '} = \{(x_t, y_t) \in S_{\ell} : f(x_{t, i}) = 1\}$ and $S_{\ell''} = \{(x_t, y_t) \in S_{\ell} : f(x_{t, i}) = 2\}$. Let the labels associated with $\ell'$ and $\ell''$ be, respectively, the most frequent labels in $S_{\ell'}$ and $S_{\ell''}$;
- **What is the property of a splitting criterion $\psi$ ensuring that the training error of a tree classifier does not increase after a split? Bonus points if you justify your answer with a proof.**
- **Write the formulas for at least two splitting criteria $\psi$ used in practice to build tree classifiers.**
	Some examples of functions $\psi$ used in practice are:
	1) **Gini function**: $\psi_2(p) = 2p(1-p)$;
	2) **scaled entropy**: $\psi_3(p) = -\frac{p}{2}\log_2(p) - \frac{1-p}{2}\log_2(1-p)$;
	3) $\psi_4(p) = \sqrt{p(1-p)}$.
- **What are the elements of a learning problem in statistical learning? (BONUS)**
	...
- **Write the formula for the statistical risk of a predictor $h$ with respect to a generic loss function and data distribution.**
- **Write the formula for the Bayes optimal predictor for a generic loss function and data distribution.**
- **Write the formula for Bayes optimal predictor and Bayes risk for the zero-one loss.**
- **Can the Bayes risk for the zero-one loss be zero? If yes, then explain how.**
- **Write the formula for Bayes optimal predictor and Bayes risk for the square loss.**
- **Explain in mathematical terms the relationship between test error and statistical risk.**
- **State the Chernoff-Hoeffding bounds.**
- **Write the bias-variance decomposition for a generic learning algorithm $A$ and associate the resulting components to overfitting and underfitting.**
- **Write the upper bound on the estimation error of ERM run on a finite class $\mathcal{H}$ of predictors. Bonus points if you justify your answer with a proof.**
- **Write the upper bpund on the estimation error of ERM run on the class of complete binary tree predictors with at most $N$ nodes on $d$ binary features.**
- **Write the bound on the difference between risk and training error for an arbitrary complete binary tree classifier $h$ on $d$ binary features in terms of its number $N_h$ of nodes. Bonus points if you provide a short explanation on how this bound is obtained.**
- **Write the formula for the $K$-fold cross validation estimate. Explain the main quantities occurring in the formula.**
- **Write the pseudo-code for computing the nested cross validation estimate.**
- **Write the mathematical definition of consistency for an algorithm $A$.**
- **Write the statement of the no-free-lunch theorem.**
- **Write the mathematical definition of nonparametric learning algorithm. Define the main quantities occurring in the formula.**
- **Name one nonparametric learning algorithm and one parametric learning algorithm.**
- **Write the mathematical conditions on $k$ ensuring consistency for the $k-NN$ algorithm.**
- **Write the formula for the Lipschitz condition in a binary classification problem. Define the main quantities occurring in the formula.**
- **Write the rate at which the risk of a consistent learning algorithm for binary classification vanish as a function of the training set size $m$ and the dimension $d$ under Lipschitz assumptions.**
- **Explain the curse of dimensionality.**
- **Write the bound on the risk of $1-NN$ binary classifier under Lipschitz assumptions.**
- **Can the ERM over linear classifiers be computed efficiently? Can it be approximated efficiently? Motivate your answers.**
- **Write the system of linear inequalities stating the condition of linear separability for a training set for binary classfication.**
- **Write the pseudo-code for the Perceptron algorithm.**
- **Write the statement of the Perceptron convergence theorem. Bonus points if you provide the proof.**
- **Write the closed-form formula (i.e., not the argmin definition) for the Ridge Regression predictor. Define the main quantities occurring in the formula.**
- **Write the pseudo-code for the projected online gradient descent algorithm.**
- **Write the upper bound on the regret of projected online gradient descent on convex functions. Define the main quantities occurring in the bound.**
- **Write the upper bound on the regret of online gradient descent on $\sigma$-strongly convex functions. Define the main quantities occurring in the bound.**
- **Write the formula for the hinge loss.**
- **Write the mistake bound for the Perceptron run on an arbitrary data stream for binary classification. Define the main quantities occurring in the bound.**
- **Write the formula for the polynomial kernel of degree $n$.**
- **Write the formula for the Gaussian kernel with parameter $\gamma$.**
- **Write the pseudo-code for the kernel Perceptron algorithm.**
- **Write the mathematical definition of the linear space $\mathcal{H}_K$ of functions induced by a kernel $K$.**
- **Let $f$ be an element of the linear space $\mathcal{H}_K$ induced by a kernel $K$. Write $f(x)$ in terms of $K$.**
- **Write the statement of the Perceptron convergence theorem when the Perceptron is run with a kernel $K$. Define the main quantities occurring in the bound. (BONUS)**
- **Write the mistake bound of the Perceptron convergence theorem when the Perceptron is run with a kernel $K$. Define the main quantities occurring in the bound.**
- **Write the mistake bound for the kernel Perceptron run on an arbitrary data stream for binary classification. Define the main quantities occurring in the bound.**
- **Write the closed-form formula (i.e., not the argmin definition) of the kernel version of the Ridge Regression predictor.**
- **Write the convex optimization problem with linear constraints that defines the SVM hyperplane in the linearly separable case.**
- **Write the unconstrained optimization problem whose solution defines the SVM hyperplane when the training set is not necessarily linearly separable.**
- **Write the bound on the expected value of the SVM objective function achieved by Pegasos. Provide also a bound on the expected squared norm of the loss gradient.**
- **Write the definition of $\varepsilon$-stability for a learning algorithm.**
- **Write the value of $\varepsilon$ for which SVM is known to be stable. The value depends on the radius $X$ of the ball where the training datapoints live, the training set size $m$, and the regularization coefficient $\lambda$.**
- **Write the mathematical conditions on the regularization coefficient $\lambda$ ensuring consistency for the SVM algorithm wih Gaussian kernel.**
- **Consider the class $\mathcal{F}_d$ of all functions of the form $f : \{−1, 1\}^d \to \{−1, 1\}$. Let $\mathcal{F}_{G,\operatorname{sgn}}$ be the class of functions computed by a feedforward neural networks with the $\operatorname{sgn}$ activation function and graph $G = (V, E)$. Provide asymptotic upper and lower bounds on $\vert V \vert$ such that $\mathcal{F}_d \subseteq \mathcal{F}_{G,\operatorname {sgn}}$.**
- **Define a class of neural networks for which the ERM problem with the square loss is probably NP-hard.**
- **Write the update line of the stochastic gradient descent algorithm. Explain the main quantities.**
- **Write the definition of logistic loss for logistic regression with linear models.**
- **Write the definition of consistency for surrogate losses.**
- **Write a sufficient condition for consistency of a surrogate loss.**
- **Write the formula for Bayes optimal predictor and Bayes risk for the logistic loss.**