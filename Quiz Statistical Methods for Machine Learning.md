# Quiz list for the written test

- **Write the formula for the square loss, the zero-one loss, and the logarithmic loss.**
	The square loss formula is $\ell(y, \widehat{y}) = (y - \widehat{y})^2$;
	the zero-one loss is $\ell(y, \widehat{y}) = \cases{1 \quad \text{ if } y \neq \widehat{y} \cr \cr 0 \quad \text{ otherwise }}$
	the logarithmic loss is $\ell(y, \widehat{y}) = \cases{\ln{\frac{1}{\widehat{y}}} \quad \text{ if } y = 1 \cr \cr \ln{\frac{1}{1 - \widehat{y}}} \quad \text{ if } y = 0}$
- **What is the mathematical definition of predictor?(BONUS)**
	Given the set $\mathcal{X}$ of all possible data points for a given learning problem and given the set $\mathcal{Y}$ of all possible labels, a predictor is a function $f: \mathcal{X} \to \mathcal{Y}$ mapping data points to labels (or $f: \mathcal{X} \to \mathcal{Z}$ if the predictions belong to a set $\mathcal{Z}$ different from $\mathcal{Y}$).
- **Write the mathematical formula defining the training error of a predictor $h$.**
	The training error or empirical risk is $\ell_s(h) = \frac{1}{m}\sum_{t=1}^{m}\ell(y_t, h(\mathbf{x}_t))$.
- **What does a learning algorithm receive in input? And what does it produce in output?**
	A learning algorithm receives a training set in input and it produces a predictor in output. A training set $S$ is a set of examples $\{(x_1, y_1), ..., (x_m, y_m)\}$, where $x$ is a data point and $y$ is the corresponding label.
- **Write the mathematical formula defining the ERM algorithm over a class $\mathcal{H}$ of predictors. Define the main quantities occurring in the formula.**
	Given a class $\mathcal{H}$ of predictors and a loss function $\ell$, the Empirical Risk Minimizer is the learning algorithm that outputs some predictors minimizing the empirical risk on the training set $S$. The mathematical formula is $\widehat{f} \in \underset{f \in \mathcal{H}}{\operatorname{argmin}} \ell_S(f)$. The $\widehat{f} \in$ notation takes into account the fact that there could be multiple $f \in \mathcal{H}$ minimizing the training error.
- **How do you define overfitting and underfitting in terms of behavior of an algorithm on training and test set?**
	it is possible to give specific names to the two ways of failing for a generic learning algorithm $A$, that is, when it returns a predictor with high test error :
	- if $A$ fails by returning predictors with high training error, then we say that $A$ is **underfitting**;
	- if $A$ fails by returning predictors with low training error, then we say that $A$ is **overfitting**.
- **Name and describe three reasons why labels may be noisy.**
	Noise may occur for at least three (not mutually exclusive) reasons:
	1) **human in the loop**: the labels are assigned by a human annotator who decides the “true” label for each data point. In this case, different annotators may have different opinions;
	2) **epistemic uncertainty**: each data point is represented by a feature vector $x$ that does not contain enough information to uniquely determine the label;
	3) **aleatoric uncertainty**: the feature vector $x$ representing a data point is obtained through noisy measurements. The label associated with a given $x$ is then stochastic because the same $x$ could have been generated by different data points.
	Noisy labels cause overfitting because they may mislead the algorithm with regard to what is the “true” label for a given data point.
- **Write a short pseudo-code for the $k-NN$ algorithm for binary classification. (BONUS)**
	In order to compute $h_{k−NN}(x)$, the following operations are performed:
	1) find the $k$ training points $x_{t_1} ,..., x_{t_k}$ closest to $x$. Let $y_{t_1} ,...,y_{t_k}$ be their labels;
	2) if the majority of the labels $y_{t_1} ,...,y_{t_k}$ is $+1$, then $h_{k−NN}(x) = +1$; if the majority is $−1$, then $h_{k−NN}(x) = −1$.
- **Is $k-NN$ more likely to overfit when $k$ is large or small?**
	The learning algorithm suffers from high test error for small values of $k$ (overfitting) and for large values of $k$ (underfitting).
- **Write a short pseudo-code for building a tree classifier based on a training set $S$.**
	1) **initialization**: create a tree $T$ with only the root $\ell$ and let $S_\ell = S$. Let the label associated with the root be the most frequent label in $S_\ell$;
	2) **main loop**: pick a leaf $\ell$ and replace it with an internal node $v$ creating two children $\ell'$ (first child) and $\ell''$ (second child). Pick an attribute $i$ and a test $f : \mathcal{X}_i \to \{1,2\}$. Associate the test $f$ with $v$ and partition $S_\ell$ in the two subsets $S_{\ell '} = \{(x_t, y_t) \in S_{\ell} : f(x_{t, i}) = 1\}$ and $S_{\ell''} = \{(x_t, y_t) \in S_{\ell} : f(x_{t, i}) = 2\}$. Let the labels associated with $\ell'$ and $\ell''$ be, respectively, the most frequent labels in $S_{\ell'}$ and $S_{\ell''}$;
- **What is the property of a splitting criterion $\psi$ ensuring that the training error of a tree classifier does not increase after a split? Bonus points if you justify your answer with a proof.**
	The property of a splitting criterion $\psi$ ensuring that the training error of a tree classifier does not increase after a split is the fact that $\psi$ is a concave function.
	To prove it, we can utilize Jensen's inequality, stating that $\psi(\alpha a + (1 -\alpha)b) \geq \alpha \psi (a) + (1 - \alpha) \psi (b) \quad \forall a, b \in \mathbb{R} \text{ and all } \alpha \in [0,1]$.<br />
	We can study how the training error changes when $\ell$ is replaced by two new leaves $\ell'$ and $\ell''$, $\underbrace{\psi \Big ( \frac{N^+_\ell}{N_\ell} \Big)N_\ell}_{\text{contribution of }\ell \text { to the training error}} = \psi \Big ( \frac{N^+_{\ell'}}{N_\ell} + \frac{N^+_{\ell''}}{N_\ell} \Big)N_\ell = \psi \Big ( \frac{N^+_{\ell'}}{N_\ell} \frac{N_{\ell'}}{N_{\ell'}} + \frac{N^+_{\ell''}}{N_\ell}\frac{N_{\ell''}}{N_{\ell''}} \Big)N_\ell =$
	At this point it is possible to apply Jensen's inequality: $= \psi \Big ( \text{ }\underbrace{\frac{N^+_{\ell'}}{N_{\ell'}}}_{a} \underbrace{\frac{N_{\ell'}}{N_\ell}}_{\alpha} + \underbrace{\frac{N^+_{\ell''}}{N_{\ell''}}}_{b} \underbrace{\frac{N_{\ell''}}{N_{\ell}}}_{1- \alpha} \text{ } \Big ) N_{\ell} \geq \psi \Big( \text{ }\underbrace{\frac{N^+_{\ell'}}{N_{\ell'}}}_{a} \text { }\Big) \underbrace{\frac{N_{\ell'}}{N_{\ell}}}_{\alpha}N_{\ell} + \psi \Big( \text{ } \underbrace{\frac{N^+_{\ell''}}{N_{\ell''}}}_{b} \text{ } \Big ) \underbrace{\frac{N_{\ell''}}{N_\ell}}_{1-\alpha} N_{\ell} =$
	$= \underbrace{\psi \Big ( \frac{N^+_\ell}{N_\ell} \Big)N_\ell}_{\text{contribution of }\ell} \geq \underbrace{\psi \Big(\frac{N^+_{\ell'}}{N_{\ell'}} \Big )N_{\ell'}}_{\text{contribution of }\ell'} + \underbrace{\psi \Big ( \frac{N^+_{\ell''}}{N_{\ell''}}\Big )N_{\ell''}}_{\text{contribution of }\ell''}$
	meaning that a split never increases the training error (recall that $N_{\ell'}^+ + N_{\ell''}^+ = N_{\ell}^+$).
- **Write the formulas for at least two splitting criteria $\psi$ used in practice to build tree classifiers.**
	Some examples of functions $\psi$ used in practice are:
	1) Gini function: $\psi_2(p) = 2p(1-p)$;
	2) scaled entropy: $\psi_3(p) = -\frac{p}{2}\log_2(p) - \frac{1-p}{2}\log_2(1-p)$;
	3) $\psi_4(p) = \sqrt{p(1-p)}$.
- **What are the elements of a learning problem in statistical learning? (BONUS)**
	In statistical learning, a **problem** is fully speciﬁed by a pair $(\mathcal{D}, \ell)$, where $\mathcal{D}$ is the data distribution and $\ell$ is a loss function.
- **Write the formula for the statistical risk of a predictor $h$ with respect to a generic loss function and data distribution.**
	The performance of a predictor $h : \mathcal{X} \to \mathcal{Y}$ with respect to $(\mathcal{D}, \ell)$, where $\mathcal{D}$ is a generic data distribution and $\ell$ is a generic loss function, is evaluated via the statistical risk, deﬁned by $\ell_{\mathcal{D}}(h) = \mathbb{E}[\ell(Y, h(X))]$. This is the expected value of the loss function on a random example $(X, Y)$ drawn from $\mathcal{D}$.
- **Write the formula for the Bayes optimal predictor for a generic loss function and data distribution.**
	The best possible predictor $f^*: \mathcal{X} \to \mathcal{Y}$ given $\mathcal{D}$ is known as Bayes optimal predictor, and is deﬁned by $f^*(x) = \underset{\widehat{y} \in \mathcal{Y}}{\operatorname{argmin}} \text{ } \mathbb{E}[\ell(Y, \widehat{y}) \vert X = x]$ where $\widehat{y} \in \mathcal{Y}$ is the value for which the conditional risk $\mathbb{E}[\ell(Y, \widehat{y}) \vert X = x]$ attains its minimum.
- **Write the formula for Bayes optimal predictor and Bayes risk for the zero-one loss.**
	Let $\eta(x)$ be the probability of $Y = 1$ conditioned on $X = x$. We view $\eta(x) = \mathbb{P}( Y = +1 \text{ } \vert \text{ } X = x)$ as the value on $x$ of a function $\eta: \mathcal{X} \to [0, 1]$. Let $\mathbb{I}\{A\} \in \{0, 1\}$ be the **indicator function** of an event $A$, that is, $\mathbb{I}\{A\} = 1$ if and only if $A$ occurs.<br /> The statistical risk with respect to the zero-one loss $\ell(y, \widehat{y}) = \mathbb{I}\{\widehat{y} \neq y\}$ is therefore defined by $\ell_{\mathcal{D}}(h) = \mathbb{E}\big[\ell(Y, h(X))\big] = \mathbb{E}\big[\mathbb{I}\{h(X) \neq Y \}\big] =$ 
	$= 1 \cdot \mathbb{P}(h(X) \neq Y) + 0 \cdot \mathbb{P}(h(X) = Y) =  \mathbb{P}(h(X) \neq Y)$<br />
	The Bayes optimal predictor $f^*: \mathcal{X} \to \{−1, 1\}$ for binary classiﬁcation is derived as follows $\quad f^*(x) = \underset{\widehat{y} \in \{-1, 1\}}{\operatorname{argmin}}\mathbb{E}\big[\ell(Y, \widehat{y}) \text{ } \vert \text{ } X = x\big]$
	$= \underset{\widehat{y} \in \{-1, 1\}}{\operatorname{argmin}}\mathbb{E}\Big[\mathbb{I}\big\{Y = +1\big\}\mathbb{I}\big\{\widehat{y} = -1\big\} + \mathbb{I}\big\{Y = -1\big\}\mathbb{I}\big\{\widehat{y} = +1\big\} \text{ } \vert \text{ } X = x\Big]$
	$= \underset{\widehat{y} \in \{-1, 1\}}{\operatorname{argmin}}\Big (  \mathbb{E}\big[\mathbb{I}\{Y = +1\} \vert X = x\big]\mathbb{I}\{\widehat{y} = -1\} +  \mathbb{E}\big[\mathbb{I}\{Y = -1\} \vert X = x\big]\mathbb{I}\{\widehat{y} = +1\}\Big )$
	$= \underset{\widehat{y} \in \{-1, 1\}}{\operatorname{argmin}}\Big(\mathbb{P}\big(Y =  + 1 \text{ } \vert \text{ } X = x\big)\mathbb{I}\{\widehat{y} = -1\} + \mathbb{P}\big(Y = -1 \text{ } \vert \text{ } X = x\big)\mathbb{I}\{\widehat{y} = +1\}\Big)$
	$=\underset{\widehat{y} \in \{-1, 1\}}{\operatorname{argmin}}\Big(\eta(x) \mathbb{I}\{\widehat{y}= -1\} + (1 - \eta(x))\mathbb{I}\{\widehat{y} = +1\}\Big)$<br />
	If $\widehat{y} = 1$, the first term goes to $0$ and we predict the second term. Viceversa, we predict the first term. The algorithm should, then, predict $-1$ when $\eta(x) < (1 - \eta(x))$. So $f^*(x)= \cases{-1 \quad \text{if } \eta(x) < \frac{1}{2} \cr \cr +1 \quad \text{if } \eta(x) \geq \frac{1}{2}}$<br />
	Hence, the Bayes optimal classifier predicts the label whose probability is the highest when conditioned on the instance. Finally, it is easy to verify that the Bayes risk in this case is $\ell_{\mathcal{D}}(f^*) = \mathbb{E}[\ell(f^*(X), Y)] = \mathbb{E}\big[\mathbb{I}\{f^*(X) \neq Y\}\big] = \mathbb{P}(f^*(X) \neq Y)$<br />
	Knowing that $\mathbb{P}(f^*(X) \neq Y \vert X = x) = \operatorname{min} \{\eta(x), (1 - \eta(x))\}$ and knowing that $\mathbb{E}\Big[\mathbb{E}\big[\mathbb{I}\{f^*(x) \neq Y\}\big \vert X = x]\Big] = \mathbb{E}[\mathbb{I}\{f^*(x) \neq Y\}\big]$, it is possible to define $\ell_{\mathcal{D}}(f^*) = \mathbb{E}\big[min\{\eta(X), 1 - \eta(X)\}\big]$.<br /><br />
	That is, the Bayes risk is the expectation of the probability of the event that is less likely to happen conditioned on the instance.
- **Can the Bayes risk for the zero-one loss be zero? If yes, then explain how.**
	
- **Write the formula for Bayes optimal predictor and Bayes risk for the square loss.**
	The Bayes optimal predictor for the square loss is $f^*(x) = \mathbb{E}\big[Y \text{ } \vert \text{ } X = x\big]$ and the Bayes risk for the square loss is $\ell_{\mathcal{D}}(f^*) =  Var\big[Y \vert X = x\big]$.<br />
	We now compute the Bayes optimal predictor $f^*$ for the quadratic loss function $\ell(y, \widehat{y}) = (y − \widehat{y})^2$ when $\mathcal{Y} \equiv \mathbb{R}$, $f^*(x) = \underset{\widehat{y} \in \mathbb{R}}{\operatorname{argmin}} \mathbb{E}\Big[(Y - \widehat{y})^2 \text{ } \vert \text{ } X = x\Big]$<br />
	$= \underset{\widehat{y} \in \mathbb{R}}{\operatorname{argmin}} \mathbb{E}\Big[Y^2 + \widehat{y}^2 -2\widehat{y}Y \text{ } \vert \text{ } X = x\Big]$<br />
	Because we are interested in the minimizing of $\widehat{y}$, it is possible to notice that the term $Y^2$ is a costant and, in fact, it does not depend on $\widehat{y}$. Using the linear property of expectation $\mathbb{E}[aX + bY] = a\mathbb{E}[X] + b\mathbb{E}[Y], \quad a, b \in \mathbb{R}$, we are able to write $= \underset{\widehat{y} \in \mathcal{Y}}{\operatorname {argmin}}\Big(\underbrace{\mathbb{E}\big[Y^2 \text{ }\vert \text{ }X = x \big]}_{\text{does not depend on }\widehat{y}} + \widehat{y}^2 - 2 \widehat{y} \mathbb{E} \big[Y \text{ }\vert \text{ }X = x\big] \Big)$<br />
	$= \underset{\widehat{y} \in \mathbb{R}}{\operatorname {argmin}}\Big( \widehat{y}^2 - 2\widehat{y} \mathbb{E}\big[Y \vert X = x\big]\Big)\quad \text{ } \quad (\text{ignoring the term that does not depend on } \widehat{y})$<br />
	and the reason why this is possible is because the term ignored is just a costant and so it is possible to extract it from the $\operatorname{argmin}$ operator.<br />
	Now, we have to minimize the function $F(\widehat{y}) = \widehat{y}^2 - 2\widehat{y}\mathbb{E}\big[Y \text{ } \vert \text{ } X = x\big]$, which can be seen as $F(z) = z^2 - 2zc$. Its derivative is $F'(z) = 2z -2c$ and it is minimized for $F'(z) = 0$. After the substitution in the derivative, we obtain $2 \widehat{y} - 2c = 2 \widehat{y} - 2 \mathbb{E}\big[Y \vert X = x\big] = 0$ and, therefore 
	$f^*(x) = \mathbb{E}\big[Y \text{ } \vert \text{ } X = x\big]$<br />
	Thus, the Bayes optimal prediction for the quadratic loss function is the expected value of the label conditioned on the instance. So, if it is desired to minimize the loss, the expectation must be predicted.
	Substituting in the conditional risk formula $\mathbb{E}[(Y - f^*(X))^2 \vert X = x]$ the Bayes optimal predictor $f^*(X) = \mathbb{E}[Y \text{ }\vert \text{ } X = x]$ we obtain
	$\mathbb{E}\Big[\big(Y - f^*(X)\big)^2 \text{ }\Big \vert \text{ } X = x \Big] = \mathbb{E}\Big[\big(Y - \mathbb{E}[Y \text{ } \vert \text{ } X = x ]\big)^2 \text{ }\Big \vert \text{ } X = x \Big] = Var\big[Y \vert X = x\big]$<br />
	In words, the conditional risk of the Bayes optimal predictor for the quadratic loss is the **conditional variance**, the variance of the label conditioned on the instance. By averaging over $X$ we obtain $\ell_{\mathcal{D}}(f^*) = \mathbb{E}\big[Var[Y \text{ } \vert \text{ } X]\big]$
- **Explain in mathematical terms the relationship between test error and statistical risk.**
- **State the Chernoff-Hoeffding bounds.**
- **Write the bias-variance decomposition for a generic learning algorithm $A$ and associate the resulting components to overfitting and underfitting.**
- **Write the upper bound on the estimation error of ERM run on a finite class $\mathcal{H}$ of predictors. Bonus points if you justify your answer with a proof.**
- **Write the upper bpund on the estimation error of ERM run on the class of complete binary tree predictors with at most $N$ nodes on $d$ binary features.**
- **Write the bound on the difference between risk and training error for an arbitrary complete binary tree classifier $h$ on $d$ binary features in terms of its number $N_h$ of nodes. Bonus points if you provide a short explanation on how this bound is obtained.**
- **Write the formula for the $K$-fold cross validation estimate. Explain the main quantities occurring in the formula.**
- **Write the pseudo-code for computing the nested cross validation estimate.**
- **Write the mathematical definition of consistency for an algorithm $A$.**
- **Write the statement of the no-free-lunch theorem.**
- **Write the mathematical definition of nonparametric learning algorithm. Define the main quantities occurring in the formula.**
- **Name one nonparametric learning algorithm and one parametric learning algorithm.**
- **Write the mathematical conditions on $k$ ensuring consistency for the $k-NN$ algorithm.**
- **Write the formula for the Lipschitz condition in a binary classification problem. Define the main quantities occurring in the formula.**
- **Write the rate at which the risk of a consistent learning algorithm for binary classification vanish as a function of the training set size $m$ and the dimension $d$ under Lipschitz assumptions.**
- **Explain the curse of dimensionality.**
- **Write the bound on the risk of $1-NN$ binary classifier under Lipschitz assumptions.**
- **Can the ERM over linear classifiers be computed efficiently? Can it be approximated efficiently? Motivate your answers.**
- **Write the system of linear inequalities stating the condition of linear separability for a training set for binary classfication.**
- **Write the pseudo-code for the Perceptron algorithm.**
- **Write the statement of the Perceptron convergence theorem. Bonus points if you provide the proof.**
- **Write the closed-form formula (i.e., not the argmin definition) for the Ridge Regression predictor. Define the main quantities occurring in the formula.**
- **Write the pseudo-code for the projected online gradient descent algorithm.**
- **Write the upper bound on the regret of projected online gradient descent on convex functions. Define the main quantities occurring in the bound.**
- **Write the upper bound on the regret of online gradient descent on $\sigma$-strongly convex functions. Define the main quantities occurring in the bound.**
- **Write the formula for the hinge loss.**
- **Write the mistake bound for the Perceptron run on an arbitrary data stream for binary classification. Define the main quantities occurring in the bound.**
- **Write the formula for the polynomial kernel of degree $n$.**
- **Write the formula for the Gaussian kernel with parameter $\gamma$.**
- **Write the pseudo-code for the kernel Perceptron algorithm.**
- **Write the mathematical definition of the linear space $\mathcal{H}_K$ of functions induced by a kernel $K$.**
- **Let $f$ be an element of the linear space $\mathcal{H}_K$ induced by a kernel $K$. Write $f(x)$ in terms of $K$.**
- **Write the statement of the Perceptron convergence theorem when the Perceptron is run with a kernel $K$. Define the main quantities occurring in the bound. (BONUS)**
- **Write the mistake bound of the Perceptron convergence theorem when the Perceptron is run with a kernel $K$. Define the main quantities occurring in the bound.**
- **Write the mistake bound for the kernel Perceptron run on an arbitrary data stream for binary classification. Define the main quantities occurring in the bound.**
- **Write the closed-form formula (i.e., not the argmin definition) of the kernel version of the Ridge Regression predictor.**
- **Write the convex optimization problem with linear constraints that defines the SVM hyperplane in the linearly separable case.**
- **Write the unconstrained optimization problem whose solution defines the SVM hyperplane when the training set is not necessarily linearly separable.**
- **Write the bound on the expected value of the SVM objective function achieved by Pegasos. Provide also a bound on the expected squared norm of the loss gradient.**
- **Write the definition of $\varepsilon$-stability for a learning algorithm.**
- **Write the value of $\varepsilon$ for which SVM is known to be stable. The value depends on the radius $X$ of the ball where the training datapoints live, the training set size $m$, and the regularization coefficient $\lambda$.**
- **Write the mathematical conditions on the regularization coefficient $\lambda$ ensuring consistency for the SVM algorithm wih Gaussian kernel.**
- **Consider the class $\mathcal{F}_d$ of all functions of the form $f : \{−1, 1\}^d \to \{−1, 1\}$. Let $\mathcal{F}_{G,\operatorname{sgn}}$ be the class of functions computed by a feedforward neural networks with the $\operatorname{sgn}$ activation function and graph $G = (V, E)$. Provide asymptotic upper and lower bounds on $\vert V \vert$ such that $\mathcal{F}_d \subseteq \mathcal{F}_{G,\operatorname {sgn}}$.**
- **Define a class of neural networks for which the ERM problem with the square loss is probably NP-hard.**
- **Write the update line of the stochastic gradient descent algorithm. Explain the main quantities.**
- **Write the definition of logistic loss for logistic regression with linear models.**
- **Write the definition of consistency for surrogate losses.**
- **Write a sufficient condition for consistency of a surrogate loss.**
- **Write the formula for Bayes optimal predictor and Bayes risk for the logistic loss.**